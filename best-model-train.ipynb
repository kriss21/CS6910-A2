{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D,Dense,Activation,MaxPooling2D,Flatten,BatchNormalization,Dropout,InputLayer\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn_model:\n",
    "    def __init__(self,input_shape):\n",
    "        self.input_shape = input_shape\n",
    "        self.model = Sequential()\n",
    "        self.model.add(InputLayer(input_shape=input_shape))\n",
    "        \n",
    "    def add_cnn_block(self,nfilters=16,filter_size=(2,2),activation='relu',pool_size=(2,2),batch_norm='yes',dropout=None):\n",
    "        self.model.add(Conv2D(nfilters,filter_size,padding=\"same\"))\n",
    "        if batch_norm == 'yes':\n",
    "            self.model.add(BatchNormalization())\n",
    "        self.model.add(Activation(activation))\n",
    "        if dropout is not None:\n",
    "            self.model.add(Dropout(dropout))\n",
    "        self.model.add(MaxPooling2D(pool_size=pool_size))\n",
    "        \n",
    "    def add_dense_layer(self,neurons=16):\n",
    "        self.model.add(Flatten())\n",
    "        self.model.add(Dense(neurons,activation='relu'))\n",
    "        \n",
    "    def build_model(self,output,loss='categorical_crossentropy',lr=1e-4):\n",
    "        self.model.add(Dense(output,activation='softmax'))\n",
    "        optz = keras.optimizers.Adam(lr)\n",
    "        self.model.compile(optimizer=optz,loss=loss,metrics=['accuracy'])\n",
    "#         self.model.summary()\n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8999 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "pref = '../inaturalist_12K/'\n",
    " \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    pref+'train',\n",
    "    target_size=(224,224),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical')\n",
    "\n",
    "val_generator = test_datagen.flow_from_directory(\n",
    "    pref+'val',\n",
    "    target_size=(224,224),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Amphibia',\n",
       " 'Animalia',\n",
       " 'Arachnida',\n",
       " 'Aves',\n",
       " 'Fungi',\n",
       " 'Insecta',\n",
       " 'Mammalia',\n",
       " 'Mollusca',\n",
       " 'Plantae',\n",
       " 'Reptilia']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = list(train_generator.class_indices.keys())\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(filters,filter_size,batch_norm,dropout,dense_size,lr):\n",
    "    keras.backend.clear_session()\n",
    "    model = cnn_model((224,224,3))\n",
    "    for i in range(5):\n",
    "        model.add_cnn_block(nfilters=filters[i],filter_size=filter_size[i],batch_norm=batch_norm,dropout=dropout)\n",
    "    model.add_dense_layer(dense_size)\n",
    "    training = model.build_model(10,lr=lr)\n",
    "    return training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "flts = [32,64,128,256,512]\n",
    "fltsz = [(11,11),(7,7),(5,5),(3,3),(2,2)]\n",
    "best = make_model(flts,fltsz,\"yes\",0,128,1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100/100 [==============================] - 32s 320ms/step - loss: 1.5655 - accuracy: 0.4481 - val_loss: 1.7899 - val_accuracy: 0.3878\n",
      "Epoch 2/20\n",
      "100/100 [==============================] - 35s 355ms/step - loss: 1.5609 - accuracy: 0.4575 - val_loss: 1.8920 - val_accuracy: 0.3375\n",
      "Epoch 3/20\n",
      "100/100 [==============================] - 36s 361ms/step - loss: 1.5534 - accuracy: 0.4588 - val_loss: 1.9393 - val_accuracy: 0.3250\n",
      "Epoch 4/20\n",
      "100/100 [==============================] - 37s 373ms/step - loss: 1.5265 - accuracy: 0.4663 - val_loss: 1.9427 - val_accuracy: 0.3189\n",
      "Epoch 5/20\n",
      "100/100 [==============================] - 39s 393ms/step - loss: 1.5636 - accuracy: 0.4544 - val_loss: 1.7904 - val_accuracy: 0.3875\n",
      "Epoch 6/20\n",
      "100/100 [==============================] - 43s 431ms/step - loss: 1.4847 - accuracy: 0.4881 - val_loss: 2.0099 - val_accuracy: 0.3214\n",
      "Epoch 7/20\n",
      "100/100 [==============================] - 44s 438ms/step - loss: 1.5387 - accuracy: 0.4576 - val_loss: 1.8198 - val_accuracy: 0.3575\n",
      "Epoch 8/20\n",
      "100/100 [==============================] - 44s 441ms/step - loss: 1.5261 - accuracy: 0.4769 - val_loss: 1.9224 - val_accuracy: 0.3087\n",
      "Epoch 9/20\n",
      "100/100 [==============================] - 44s 443ms/step - loss: 1.4920 - accuracy: 0.4756 - val_loss: 1.9212 - val_accuracy: 0.3075\n",
      "Epoch 10/20\n",
      "100/100 [==============================] - 44s 444ms/step - loss: 1.5171 - accuracy: 0.4881 - val_loss: 1.9805 - val_accuracy: 0.3400\n",
      "Epoch 11/20\n",
      "100/100 [==============================] - 45s 454ms/step - loss: 1.5045 - accuracy: 0.4913 - val_loss: 1.7509 - val_accuracy: 0.3597\n",
      "Epoch 12/20\n",
      "100/100 [==============================] - 45s 453ms/step - loss: 1.5427 - accuracy: 0.4670 - val_loss: 1.8610 - val_accuracy: 0.3850\n",
      "Epoch 13/20\n",
      "100/100 [==============================] - 45s 448ms/step - loss: 1.4840 - accuracy: 0.4919 - val_loss: 1.8491 - val_accuracy: 0.3546\n",
      "Epoch 14/20\n",
      "100/100 [==============================] - 43s 428ms/step - loss: 1.5296 - accuracy: 0.4663 - val_loss: 1.8103 - val_accuracy: 0.3725\n",
      "Epoch 15/20\n",
      "100/100 [==============================] - 45s 449ms/step - loss: 1.5290 - accuracy: 0.4675 - val_loss: 1.9509 - val_accuracy: 0.3350\n",
      "Epoch 16/20\n",
      "100/100 [==============================] - 46s 456ms/step - loss: 1.4894 - accuracy: 0.4831 - val_loss: 1.8050 - val_accuracy: 0.3750\n",
      "Epoch 17/20\n",
      "100/100 [==============================] - 46s 457ms/step - loss: 1.4801 - accuracy: 0.4756 - val_loss: 1.9547 - val_accuracy: 0.3150\n",
      "Epoch 18/20\n",
      "100/100 [==============================] - 45s 452ms/step - loss: 1.4647 - accuracy: 0.4984 - val_loss: 1.7974 - val_accuracy: 0.3622\n",
      "Epoch 19/20\n",
      "100/100 [==============================] - 47s 468ms/step - loss: 1.4997 - accuracy: 0.4787 - val_loss: 1.9486 - val_accuracy: 0.3475\n",
      "Epoch 20/20\n",
      "100/100 [==============================] - 46s 458ms/step - loss: 1.5048 - accuracy: 0.4769 - val_loss: 1.8123 - val_accuracy: 0.3900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb0444e8af0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best.fit(train_generator,\n",
    "        steps_per_epoch=100,\n",
    "        epochs=20,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best.save('best_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
